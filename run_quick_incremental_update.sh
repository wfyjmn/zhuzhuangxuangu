#!/bin/bash
# å¿«é€Ÿæ›´æ–°ç­–ç•¥ï¼šè¡¥å…¨ 2023-2024 å…³é”®ç‰¹å¾ï¼ˆæ¢æ‰‹ç‡/PEï¼‰+ å¤§ç›˜æŒ‡æ•°

# 1. ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
cd /workspace/projects || exit

# 2. åŠ è½½ç¯å¢ƒå˜é‡
if [ -f .env ]; then
    export $(cat .env | grep -v '^#' | xargs)
    echo "âœ… ç¯å¢ƒå˜é‡å·²åŠ è½½"
else
    echo "âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ° .env æ–‡ä»¶"
fi

echo ""
echo "ğŸš€ å¯åŠ¨å¿«é€Ÿå¢é‡æ›´æ–°..."
echo "ğŸ“… ç›®æ ‡: 2023.07.01 ~ 2024.06.30 (ä¸ªè‚¡ + æŒ‡æ•°)"

# 3. åå°è¿è¡Œ Python
nohup python3 -u -c "
import os
import sys
import time
from pathlib import Path

# ç¡®ä¿èƒ½å¯¼å…¥é¡¹ç›®æ ¹ç›®å½•çš„æ¨¡å—
project_root = Path.cwd()
sys.path.insert(0, str(project_root))

# è®¾ç½® PYTHONPATH ç¯å¢ƒå˜é‡
sys.path.insert(0, str(project_root / 'assets'))

try:
    from data_warehouse import DataWarehouse
    import tushare as ts
except ImportError as e:
    print(f'âŒ å¯¼å…¥å¤±è´¥: {e}')
    print(f'å½“å‰è·¯å¾„: {os.getcwd()}')
    print(f'PYTHONPATH: {sys.path}')
    sys.exit(1)

# é…ç½®æ—¥å¿—è¾“å‡ºæ— ç¼“å†²
sys.stdout.reconfigure(encoding='utf-8')

print('=' * 80)
print('ğŸš€ å¿«é€Ÿå¢é‡æ›´æ–° - è¡¥å…¨ç‰¹å¾ä¸æŒ‡æ•°')
print('=' * 80)

dw = DataWarehouse()
pro = ts.pro_api()  # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ Token

# ------------------------------------------------------------------
# ä»»åŠ¡ 1: æ›´æ–°å¤§ç›˜æŒ‡æ•° (ç”¨äºè®¡ç®—ç›¸å¯¹æ”¶ç›Š Label)
# ------------------------------------------------------------------
print('\n[ä»»åŠ¡ 1/2] æ›´æ–°ä¸Šè¯æŒ‡æ•° (000001.SH)...')
try:
    # ä¸‹è½½æŒ‡æ•°æ—¥çº¿
    df_index = pro.index_daily(ts_code='000001.SH', start_date='20230101', end_date='20241231')
    if not df_index.empty:
        # ä¿å­˜åˆ° data/daily ç›®å½•ï¼Œæ–‡ä»¶åæ ¼å¼ä¸å…¶ä»–è‚¡ç¥¨ä¸€è‡´
        save_path = project_root / 'assets' / 'data' / 'daily' / '000001.SH.csv'
        save_path.parent.mkdir(parents=True, exist_ok=True)
        df_index.sort_values('trade_date', inplace=True)
        df_index.to_csv(save_path, index=False)
        print(f'  âœ… æŒ‡æ•°æ•°æ®å·²ä¿å­˜: {save_path} ({len(df_index)} æ¡)')
    else:
        print('  âš ï¸  æœªè·å–åˆ°æŒ‡æ•°æ•°æ®')
except Exception as e:
    print(f'  âŒ æŒ‡æ•°æ›´æ–°å¤±è´¥: {e}')

# ------------------------------------------------------------------
# ä»»åŠ¡ 2: æ›´æ–°ä¸ªè‚¡æ•°æ® (è¡¥å…¨ turnover_rate, pe_ttm)
# ------------------------------------------------------------------
print('\n[ä»»åŠ¡ 2/2] æ›´æ–°ä¸ªè‚¡æ•°æ® (2023.07 ~ 2024.06)...')

# å®šä¹‰æ—¶é—´æ®µ
dates1 = dw.get_trade_days('20230701', '20231231')
dates2 = dw.get_trade_days('20240101', '20240630')
dates = dates1 + dates2

print(f'è®¡åˆ’æ›´æ–°å¤©æ•°: {len(dates)} å¤©')

success_count = 0
start_time = time.time()

for i, date in enumerate(dates, 1):
    try:
        # force=True ä¼šå¼ºåˆ¶é‡æ–°ä¸‹è½½å¹¶åˆå¹¶ daily_basic æ•°æ®
        df = dw.download_daily_data(date, force=True)

        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦è¡¥å…¨
        if df is not None and 'turnover_rate' in df.columns and 'pe_ttm' in df.columns:
            # ç®€å•è¿›åº¦æ¡ï¼Œä¸åˆ·å±
            if i % 10 == 0:
                print(f'  [{i}/{len(dates)}] {date} âœ… æˆåŠŸ (å«ä¼°å€¼æ•°æ®)')
            success_count += 1
        else:
            if i % 10 == 0:
                print(f'  [{i}/{len(dates)}] {date} âš ï¸ æ•°æ®ä¸‹è½½æˆåŠŸä½†ç‰¹å¾ä»ç¼ºå¤±')

    except Exception as e:
        print(f'  [{i}/{len(dates)}] {date} âŒ å¤±è´¥: {e}')

    # é¿å…è§¦å‘ Tushare é™æµ
    time.sleep(0.1)

elapsed = time.time() - start_time
print('\n' + '=' * 80)
print(f'ğŸ‰ æ›´æ–°å®Œæˆï¼')
print(f'â±ï¸  è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ')
print(f'âœ… æˆåŠŸ: {success_count}/{len(dates)} ({success_count/len(dates)*100:.1f}%)')
print('=' * 80)

if success_count > len(dates) * 0.9:
    print('\nğŸŠ æ•°æ®æ›´æ–°æˆåŠŸï¼å¯ä»¥é‡æ–°è®­ç»ƒæ¨¡å‹')
else:
    print('\nâš ï¸  éƒ¨åˆ†æ•°æ®æ›´æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—')

" > quick_incremental_update.log 2>&1 &

echo ""
echo "âœ… ä»»åŠ¡å·²åå°å¯åŠ¨"
echo "ğŸ“„ æ—¥å¿—æ–‡ä»¶: quick_incremental_update.log"
echo "ğŸ‘€ æŸ¥çœ‹å‘½ä»¤: tail -f quick_incremental_update.log"
