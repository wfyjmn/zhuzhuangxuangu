# 对话5改进说明文档

## 📋 概述

本文档记录了根据对话5.txt的需求对 DeepQuant 智能选股系统进行的改进，旨在解决模型训练结果严重未达标（AUC 0.57 vs 目标 0.65-0.70）的问题。

## 🎯 问题诊断

根据对话5.txt的分析，模型表现差的根本原因包括：

1. **"伪特征"问题**：特征工程使用了粗糙的代理指标（如 OBV、成交量倍数），而非真实的主力资金数据
2. **价格失真（未复权）**：未使用复权价格计算技术指标，导致除权日信号失真
3. **缺乏换手率**：未获取换手率数据，无法衡量真实的筹码交换强度
4. **召回率极低**：阈值策略过于保守（召回率仅 2.32%）

## ✅ 已完成的改进

### 1. 修改 `data_collector.py` - 获取真实资金流和复权数据

**文件路径**: `src/stock_system/data_collector.py`

**主要改动**:
- 修改 `get_daily_data` 方法，同时获取四张表的数据：
  - `daily`: 基础行情数据
  - `daily_basic`: 换手率、流通市值、PE、PB 等指标
  - `moneyflow`: 真实的主力资金流向数据（特大单、大单、中单、小单）
  - `adj_factor`: 复权因子

**关键代码**:
```python
# 1. 基础行情 (Open, Close, Vol)
df_daily = self.pro.daily(ts_code=ts_code, start_date=start_date, end_date=end_date)

# 2. 每日指标 (Turnover_rate, PE, PB, Circ_mv)
df_basic = self.pro.daily_basic(ts_code=ts_code, ...)

# 3. 复权因子 (用于计算真实的均线)
df_adj = self.pro.adj_factor(ts_code=ts_code, ...)

# 4. 资金流向 (必须有 Tushare 积分 2000+)
df_flow = self.pro.moneyflow(ts_code=ts_code, ...)

# 数据合并
df = df_daily.merge(df_adj, on=['ts_code', 'trade_date'], how='left')
df = df.merge(df_basic, on=['ts_code', 'trade_date'], how='left')
df = df.merge(df_flow, on=['ts_code', 'trade_date'], how='left')
```

**注意事项**:
- 使用新的缓存 key (`full_data_v2`) 以区分旧版本数据
- 填充资金流空值（停牌或无数据日）
- 复权因子使用前向填充（ffill）和默认值填充

### 2. 修改 `enhanced_features.py` - 使用真实数据和复权价格

**文件路径**: `src/stock_system/enhanced_features.py`

**主要改动**:

#### 2.1 添加 `_calculate_adj_price` 方法
```python
def _calculate_adj_price(self, df: pd.DataFrame) -> pd.DataFrame:
    """计算复权价格"""
    if 'adj_factor' in df.columns:
        df['adj_close'] = df['close'] * df['adj_factor']
        df['adj_open'] = df['open'] * df['adj_factor']
        df['adj_high'] = df['high'] * df['adj_factor']
        df['adj_low'] = df['low'] * df['adj_factor']
```

#### 2.2 修改 `create_main_capital_features` 方法
- 优先使用真实资金流数据（`buy_elg_vol`, `sell_elg_vol` 等）
- 计算以下真实特征：
  - `main_net_inflow`: 主力净流入金额（特大单+大单）
  - `main_flow_rate`: 主力净流入率
  - `main_flow_persistence`: 主力资金连红天数
  - `main_control_proxy`: 主力控盘度
  - `retail_panic_ratio`: 散户恐慌度（小单净卖出占比）
- 如果没有真实数据，回退到代理指标（OBV 等）

#### 2.3 修改 `create_technical_indicators_features` 方法
- 所有技术指标（MA、MACD、RSI、KDJ、ATR）均使用复权价格计算
- 避免除权日信号失真

**关键代码**:
```python
# 先计算复权价格
df = self._calculate_adj_price(df)

# 使用复权价格计算指标
price_col = 'adj_close'
df['ma_5'] = df[price_col].rolling(5).mean()
df['macd'] = df[price_col].ewm(span=12).mean() - df[price_col].ewm(span=26).mean()
```

### 3. 创建改进的训练配置文件

**文件路径**: `config/precision_priority_v4_config.json`

**主要配置**:

#### 数据配置
- `start_date`: "2021-01-01"
- `end_date`: "2024-01-01"
- `n_stocks`: 300（从 100 提升至 300）
- `min_return_threshold`: 0.05（从 0.03 提升至 0.05）

#### 特征工程配置
- `use_adj_price`: true（使用复权价格）
- `use_money_flow`: true（使用真实资金流）

#### 训练特征列表（20+ 个特征）
包含以下核心维度：
1. **主力资金维度**：`main_flow_rate`, `main_flow_persistence`, `retail_panic_ratio` 等
2. **量价结构维度**：`turnover_rate`, `volume_ratio_5`, `volume_price_correlation` 等
3. **技术指标维度**：`rsi_6`, `macd`, `ma_20`, `atr_14` 等
4. **市场情绪维度**：`stock_sentiment`, `up_down_ratio`, `sentiment_cycle` 等

#### Optuna 参数空间
- `scale_pos_weight`: 3.0 ~ 8.0（强制模型重视正样本，解决召回率低的问题）
- `max_depth`: 3 ~ 6（防止过拟合）
- `min_child_weight`: 10 ~ 30（抑制异常波动）
- `learning_rate`: 0.01 ~ 0.1（对数空间）
- 其他正则化参数

#### 阈值配置
- `target_precision`: 0.60（降低至 60%，以换取更好的召回率）
- `threshold_range`: [0.40, 0.80]（扩大搜索范围）

### 4. 创建训练脚本

**文件路径**: `scripts/train_auto_optuna.py`

**功能**:
1. 加载配置和数据
2. 获取股票池（300 只）
3. 采集数据并计算特征（包含资金流和复权价格）
4. 生成标签（5% 涨幅 + 换手率过滤 + 主力资金流入）
5. 使用 Optuna 自动调参（100 次试验）
6. 时间序列交叉验证（5 折）
7. 评估模型性能（精确率、召回率、F1、AUC）
8. 保存最佳模型

**使用方法**:
```bash
python scripts/train_auto_optuna.py
```

**预期结果**:
- AUC: 0.68-0.78（模型区分能力显著提升）
- 精确率: 55-65%
- 召回率: 20-30%（从 2.32% 大幅提升）
- F1 分数: 0.30-0.45

### 5. 创建测试脚本

**文件路径**: `scripts/test_improvements.py`

**功能**:
1. 测试数据采集是否能获取资金流和复权因子
2. 测试特征工程是否能正确计算特征
3. 验证数据质量（缺失值、异常值检查）

**使用方法**:
```bash
python scripts/test_improvements.py
```

## 🔧 使用前准备

### 1. 配置 Tushare Token

确保在环境变量中配置了 Tushare Token：
```bash
export TUSHARE_TOKEN="your_tushare_token_here"
```

或者在 `config/tushare_config.json` 中配置：
```json
{
  "token": "your_tushare_token_here",
  "max_workers": 5,
  "timeout": 30,
  "retry_count": 3,
  "rate_limit_delay": 0.1,
  "cache_expiry_hours": 24
}
```

### 2. 清理旧缓存

由于数据结构发生了变化，建议清理旧缓存：
```bash
rm -rf assets/data/market_cache/*.pkl
```

### 3. 安装依赖

确保已安装必要的 Python 包：
```bash
pip install pandas numpy xgboost optuna tushare scikit-learn
```

## 📊 预期改进效果

| 指标 | 改进前 | 改进后（预期） | 说明 |
|------|--------|----------------|------|
| AUC | 0.5743 | 0.68-0.78 | 模型区分能力显著提升 |
| 精确率 | 49.42% | 55-65% | 稳定在合理范围 |
| 召回率 | 2.32% | 20-30% | 大幅提升，不再错过机会 |
| F1 分数 | 0.044 | 0.30-0.45 | 平衡精确率和召回率 |

## 🚀 后续步骤

1. **运行训练脚本**:
   ```bash
   python scripts/train_auto_optuna.py
   ```

2. **检查训练结果**:
   - 查看最佳参数
   - 检查特征重要性
   - 验证性能指标

3. **实盘预测**（可选）:
   - 创建 `predict_today.py` 脚本
   - 每日运行，获取推荐股票

4. **参数优化**（可选）:
   - 如果性能仍不达标，可以调整 Optuna 参数空间
   - 或增加训练轮次

## ⚠️ 注意事项

1. **Tushare 积分要求**:
   - 资金流数据（`moneyflow` 接口）需要 Tushare 积分 2000+
   - 如果积分不足，系统会自动回退到代理指标

2. **数据质量**:
   - 确保数据时间范围包含足够的交易日
   - 避免使用过短的时间段

3. **计算资源**:
   - 训练 300 只股票可能需要 10-30 分钟
   - 建议在有足够内存的服务器上运行

4. **缓存管理**:
   - 缓存默认有效期为 24 小时
   - 可以通过 `config/tushare_config.json` 调整

## 📝 总结

本次改进针对对话5.txt中指出的核心问题进行了系统性修复：

1. ✅ **数据层面**：获取真实资金流数据、复权因子、换手率
2. ✅ **特征层面**：使用真实数据和复权价格计算特征
3. ✅ **配置层面**：优化标签阈值、调整样本权重
4. ✅ **训练层面**：使用 Optuna 自动调参、扩大特征空间

预计这些改进将显著提升模型性能，从"不可用"（AUC 0.57）提升到"生产级"（AUC 0.70+）。

## 📚 参考资料

- 对话5.txt：详细的问题诊断和解决方案
- Tushare API 文档：https://tushare.pro/document/2
- XGBoost 文档：https://xgboost.readthedocs.io/
- Optuna 文档：https://optuna.readthedocs.io/
