# -*- coding: utf-8 -*-
"""
ä¸‹è½½ 2024 å¹´æ•°æ®ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
"""

import os
import sys
import time
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from data_warehouse import DataWarehouse

def main():
    print("="*80)
    print(" " * 25 + "DeepQuant æ•°æ®ä¸‹è½½")
    print(" " * 35 + "2024 å¹´")
    print("="*80 + "\n")

    # æ£€æŸ¥ Tushare Token
    tushare_token = os.getenv("TUSHARE_TOKEN")
    if not tushare_token:
        print("âŒ é”™è¯¯ï¼šæœªé…ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡\n")
        sys.exit(1)

    print(f"âœ… Tushare Token å·²é…ç½®\n")

    # åˆå§‹åŒ–æ•°æ®ä»“åº“
    try:
        warehouse = DataWarehouse(data_dir="data/daily")
        print("âœ… æ•°æ®ä»“åº“åˆå§‹åŒ–æˆåŠŸ\n")
    except Exception as e:
        print(f"âŒ æ•°æ®ä»“åº“åˆå§‹åŒ–å¤±è´¥: {e}\n")
        sys.exit(1)

    # ä¸‹è½½èŒƒå›´ï¼ˆ2024 å¹´ï¼‰
    start_date = "20240101"
    end_date = "20241231"

    # è·å–äº¤æ˜“æ—¥åˆ—è¡¨
    trade_days = warehouse.get_trade_days(start_date, end_date)

    print(f"ğŸ“Š ä¸‹è½½é…ç½®ï¼š")
    print(f"  å¼€å§‹æ—¥æœŸ: {start_date}")
    print(f"  ç»“æŸæ—¥æœŸ: {end_date}")
    print(f"  äº¤æ˜“æ—¥æ€»æ•°: {len(trade_days)}")
    print(f"  æ•°æ®ç›®å½•: data/daily\n")

    # æ£€æŸ¥å·²ä¸‹è½½çš„æ•°æ®
    print("ğŸ“‚ æ£€æŸ¥å·²ä¸‹è½½çš„æ•°æ®...")
    downloaded_dates = []
    for date in trade_days:
        filename = os.path.join("data/daily", f"{date}.csv")
        if os.path.exists(filename):
            downloaded_dates.append(date)

    print(f"  å·²ä¸‹è½½æ•°æ®: {len(downloaded_dates)} å¤©")
    print(f"  å¾…ä¸‹è½½æ•°æ®: {len(trade_days) - len(downloaded_dates)} å¤©\n")

    # ç¡®è®¤ä¸‹è½½
    response = input("âš ï¸  æ˜¯å¦å¼€å§‹ä¸‹è½½ 2024 å¹´çš„æ•°æ®ï¼Ÿ(y/n): ")
    if response.lower() != 'y':
        print("\nâŒ ä¸‹è½½å·²å–æ¶ˆ\n")
        sys.exit(0)

    # å¼€å§‹ä¸‹è½½
    print("\n" + "="*80)
    print("å¼€å§‹ä¸‹è½½æ•°æ®...")
    print("="*80 + "\n")

    start_time = datetime.now()
    success_count = 0
    fail_count = 0
    skip_count = 0
    failed_dates = []

    try:
        for i, date in enumerate(trade_days, 1):
            filename = os.path.join("data/daily", f"{date}.csv")

            # æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½
            if os.path.exists(filename):
                print(f"[{i}/{len(trade_days)}] â­ï¸  {date} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                skip_count += 1
                continue

            print(f"[{i}/{len(trade_days)}] ğŸ“¥ ä¸‹è½½ {date}...", end=' ')

            # ä¸‹è½½æ•°æ®
            try:
                df = warehouse.download_daily_data(date)

                if df is not None:
                    success_count += 1
                    print(f"âœ… {len(df)} åªè‚¡ç¥¨")
                else:
                    fail_count += 1
                    failed_dates.append(date)
                    print(f"âŒ å¤±è´¥ï¼ˆæ— æ•°æ®ï¼‰")

                # è¿›åº¦æç¤º
                if i % 20 == 0:
                    elapsed = (datetime.now() - start_time).total_seconds()
                    avg_time = elapsed / i
                    remaining = (len(trade_days) - i) * avg_time
                    print(f"\n  [è¿›åº¦] {i}/{len(trade_days)} ({i/len(trade_days)*100:.1f}%)")
                    print(f"  [ç»Ÿè®¡] æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, è·³è¿‡: {skip_count}")
                    print(f"  [æ—¶é—´] å·²ç”¨: {elapsed/60:.1f} åˆ†é’Ÿ, é¢„è®¡å‰©ä½™: {remaining/60:.1f} åˆ†é’Ÿ\n")

                # é¿å…è§¦å‘é™æµ
                time.sleep(0.3)

            except KeyboardInterrupt:
                print(f"\n\nâš ï¸  ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­\n")
                break
            except Exception as e:
                fail_count += 1
                failed_dates.append(date)
                print(f"âŒ å¤±è´¥: {e}")

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print("\n" + "="*80)
        print("âœ… æ•°æ®ä¸‹è½½å®Œæˆï¼")
        print("="*80)
        print(f"  å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"  ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"  ç”¨æ—¶: {duration/60:.1f} åˆ†é’Ÿ")
        print(f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡ï¼š")
        print(f"  äº¤æ˜“æ—¥æ€»æ•°: {len(trade_days)}")
        print(f"  æˆåŠŸä¸‹è½½æ•°æ®: {success_count}")
        print(f"  è·³è¿‡å·²å­˜åœ¨: {skip_count}")
        print(f"  ä¸‹è½½æ•°æ®å¤±è´¥: {fail_count}")
        print(f"  æ€»è®¡: {success_count + skip_count}/{len(trade_days)} ({(success_count + skip_count)/len(trade_days)*100:.1f}%)")

        if fail_count > 0:
            print(f"\nâš ï¸  å¤±è´¥æ—¥æœŸåˆ—è¡¨ï¼š")
            for date in failed_dates[:10]:
                print(f"    - {date}")
            if len(failed_dates) > 10:
                print(f"    ... å…± {len(failed_dates)} ä¸ªå¤±è´¥")

        print()

        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        print("="*80)
        print("æ£€æŸ¥æ•°æ®å®Œæ•´æ€§...")
        print("="*80)

        missing_dates = []
        for date in trade_days:
            filename = os.path.join("data/daily", f"{date}.csv")
            if not os.path.exists(filename):
                missing_dates.append(date)

        if len(missing_dates) == 0:
            print("âœ… æ‰€æœ‰äº¤æ˜“æ—¥æ•°æ®å®Œæ•´ï¼\n")
        else:
            print(f"âš ï¸  ç¼ºå°‘ {len(missing_dates)} å¤©çš„æ•°æ®")
            print(f"  ç¼ºå¤±æ—¥æœŸ: {missing_dates[:10]}")
            if len(missing_dates) > 10:
                print(f"  ... å…± {len(missing_dates)} ä¸ªç¼ºå¤±\n")

        print("="*80)
        print("ä¸‹ä¸€æ­¥æ“ä½œï¼š")
        print("="*80)
        print("  1. ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼špython generate_training_data_2024.py")
        print("  2. è®­ç»ƒ AI è£åˆ¤ï¼špython train_ai_referee_2024.py\n")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­\n")
        print(f"  å½“å‰è¿›åº¦: {success_count + skip_count}/{len(trade_days)} å¤©å·²å®Œæˆ\n")

    except Exception as e:
        print(f"\n\nâŒ ä¸‹è½½å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
