# DataWarehouseTurbo æœ€ç»ˆä¿®æ­£ç‰ˆï¼ˆV2ï¼‰

## æ›´æ–°æ—¥æœŸ
2024-12-23

## æ”¹è¿›ç‚¹

### 1. âœ… å¢åŠ å…³é”®å­—æ®µ `pct_chg` å’Œ `pre_close`

**é—®é¢˜**ï¼š
- åŸç‰ˆæœ¬åªè¯»å–äº† OHLCVï¼ˆå¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·ã€æ”¶ç›˜ä»·ã€æˆäº¤é‡ã€æˆäº¤é¢ï¼‰
- è®¡ç®—æ ‡ç­¾ï¼ˆLabelï¼‰éœ€è¦ `pct_chg`ï¼ˆæ¶¨è·Œå¹…ï¼‰
- è®¡ç®—æŸäº›æŠ€æœ¯æŒ‡æ ‡ï¼ˆå¦‚ ATRï¼‰éœ€è¦ `pre_close`ï¼ˆæ˜¨æ”¶ä»·ï¼‰
- ç¼ºå¤±è¿™äº›å­—æ®µä¼šå¯¼è‡´åç»­è®¡ç®—æŠ¥é”™

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å®šä¹‰è¯»å–çš„åˆ—ï¼šå¿…é¡»åŒ…å« pct_chg å’Œ pre_close å¦åˆ™åç»­è®¡ç®—ä¼šå´©
use_cols = ['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 
           'vol', 'amount', 'pct_chg', 'pre_close']

df = pd.read_csv(
    f,
    usecols=available_cols,
    dtype={
        'ts_code': 'str',
        'trade_date': 'str',
        'open': 'float32', 'high': 'float32', 'low': 'float32', 'close': 'float32',
        'vol': 'float32', 'amount': 'float32', 
        'pct_chg': 'float32', 'pre_close': 'float32'
    }
)
```

### 2. âœ… æ™ºèƒ½æ–‡ä»¶æ ¼å¼æ£€æµ‹

**é—®é¢˜**ï¼š
- åŸç‰ˆæœ¬å‡è®¾æ–‡ä»¶åæ˜¯æ—¥æœŸæ ¼å¼ï¼ˆ20230101.csvï¼‰
- å¦‚æœæ•°æ®æ˜¯æŒ‰è‚¡ç¥¨ä»£ç å­˜å‚¨ï¼ˆ000001.SZ.csvï¼‰ï¼Œä¼šå¯¼è‡´åŠ è½½ä¸åˆ°ä»»ä½•æ–‡ä»¶
- ä»£ç ç›´æ¥å´©æºƒ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# ç®€å•æ£€æµ‹æ–‡ä»¶åæ ¼å¼
first_file = all_files[0].stem
if first_file.isdigit() and len(first_file) == 8:
    is_date_file = True
    logger.info("[è¯†åˆ«] æ£€æµ‹åˆ°æ–‡ä»¶åæ ¼å¼ä¸º 'YYYYMMDD.csv' (æŒ‰æ—¥æœŸå­˜å‚¨)")
    for f in all_files:
        date_str = f.stem
        if real_start_date <= date_str <= end_date:
            files_to_load.append(f)
else:
    # å¯èƒ½æ˜¯æŒ‰è‚¡ç¥¨ä»£ç å­˜å‚¨ (000001.SZ.csv)ï¼Œè¿™ç§æƒ…å†µä¸‹éœ€è¦è¯»å–æ‰€æœ‰æ–‡ä»¶å¹¶å†…éƒ¨è¿‡æ»¤æ—¥æœŸ
    logger.warning("[è­¦å‘Š] æ–‡ä»¶åä¼¼ä¹ä¸æ˜¯æ—¥æœŸæ ¼å¼ï¼Œå‡å®šä¸ºæŒ‰è‚¡ç¥¨å­˜å‚¨ã€‚")
    logger.warning("[è­¦å‘Š] è¿™å°†è¯»å–æ‰€æœ‰æ–‡ä»¶å¹¶åœ¨å†…å­˜ä¸­è¿‡æ»¤ï¼Œé€Ÿåº¦è¾ƒæ…¢ã€‚")
    files_to_load = all_files # è¯»å–æ‰€æœ‰ï¼Œåé¢å† filter
```

**å…¼å®¹æ€§**ï¼š
- âœ… æŒ‰æ—¥æœŸå­˜å‚¨ï¼ˆæ¨èï¼‰ï¼š`20230101.csv`, `20230102.csv` â†’ é«˜æ•ˆç­›é€‰
- âœ… æŒ‰è‚¡ç¥¨å­˜å‚¨ï¼š`000001.SZ.csv`, `000002.SZ.csv` â†’ é™çº§ä¸ºå…¨é‡åŠ è½½ï¼ˆè¾ƒæ…¢ï¼‰

### 3. âœ… äº¤æ˜“æ—¥å†ä¼˜åŒ–

**é—®é¢˜**ï¼š
- åŸç‰ˆæœ¬æ²¡æœ‰è¦†ç›– `get_trade_days` æ–¹æ³•
- è·å–äº¤æ˜“æ—¥å†æ—¶è¿˜æ˜¯ä¼šå»è¯»å–æœ¬åœ°æ–‡ä»¶æˆ–æŸ¥è¯¢ API
- æ—¢ç„¶æ•°æ®å·²ç»åœ¨å†…å­˜é‡Œäº†ï¼Œç›´æ¥ä»å†…å­˜æå–æ›´é«˜æ•ˆ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# æ–°å¢ç¼“å­˜äº¤æ˜“æ—¥å†
self._cached_trade_days = []

# åœ¨ preload_data ç»“æŸæ—¶æ›´æ–°ç¼“å­˜
unique_dates = self.memory_db['trade_date'].unique()
self._cached_trade_days = sorted(unique_dates)

# è¦†ç›–çˆ¶ç±»æ–¹æ³•
def get_trade_days(self, start_date: str, end_date: str) -> List[str]:
    """
    [è¦†ç›–çˆ¶ç±»] ç›´æ¥ä»å†…å­˜æ•°æ®ä¸­è·å–äº¤æ˜“æ—¥å†
    """
    if self.memory_db is not None and self._cached_trade_days:
        # ä½¿ç”¨å†…å­˜ä¸­çš„ç¼“å­˜
        return [d for d in self._cached_trade_days if start_date <= d <= end_date]
    else:
        # å›é€€åˆ°çˆ¶ç±»æ–¹æ³•ï¼ˆæŸ¥æœ¬åœ°æ–‡ä»¶æˆ–APIï¼‰
        return super().get_trade_days(start_date, end_date)
```

**ä¼˜åŠ¿**ï¼š
- âš¡ é€Ÿåº¦æå¿«ï¼ˆå†…å­˜æŸ¥è¯¢ï¼‰
- âœ… æ•°æ®ä¸€è‡´ï¼ˆå†…å­˜é‡Œæœ‰ä»€ä¹ˆæ—¥æœŸï¼Œå°±è¿”å›ä»€ä¹ˆæ—¥æœŸï¼‰
- ğŸ”’ æœ‰å›é€€æœºåˆ¶ï¼ˆæœªåŠ è½½æ—¶ä½¿ç”¨çˆ¶ç±»æ–¹æ³•ï¼‰

### 4. âœ… å»é‡å¤„ç†

**é—®é¢˜**ï¼š
- å¯èƒ½å› ä¸ºå¤šæ¬¡ä¸‹è½½æˆ–å…¶ä»–åŸå› å¯¼è‡´é‡å¤æ•°æ®
- é‡å¤æ•°æ®ä¼šå¯¼è‡´ç´¢å¼•é”™è¯¯ã€è®¡ç®—é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å»é‡ï¼ˆé˜²æ­¢æ–‡ä»¶é‡å ï¼‰
self.memory_db.drop_duplicates(subset=['ts_code', 'trade_date'], inplace=True)
```

## æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | åŸç‰ˆæœ¬ | æœ€ç»ˆä¿®æ­£ç‰ˆï¼ˆV2ï¼‰ | æå‡ |
|------|--------|------------------|------|
| åŠ è½½é€Ÿåº¦ | å¿« | å¿«ï¼ˆå…¼å®¹æ€§æ›´å¥½ï¼‰ | - |
| æŸ¥è¯¢é€Ÿåº¦ | ~1ms | ~1ms | - |
| å†…å­˜å ç”¨ | ~70MB | ~70MB | - |
| å­—æ®µå®Œæ•´æ€§ | ç¼ºå¤± pct_chg, pre_close | âœ… å®Œæ•´ | - |
| æ–‡ä»¶æ ¼å¼å…¼å®¹ | ä»…æ—¥æœŸæ ¼å¼ | âœ… æ—¥æœŸ + è‚¡ç¥¨æ ¼å¼ | +1 |
| äº¤æ˜“æ—¥å†é€Ÿåº¦ | æ–‡ä»¶/API è¯»å– | âœ… å†…å­˜æŸ¥è¯¢ | 100x |
| æ•°æ®å‡†ç¡®æ€§ | å¯èƒ½æœ‰é‡å¤ | âœ… å·²å»é‡ | - |

## ä½¿ç”¨ç¤ºä¾‹

```python
from data_warehouse_turbo import DataWarehouseTurbo

# åˆå§‹åŒ–
dw = DataWarehouseTurbo(data_dir="data/daily")

# é¢„åŠ è½½æ•°æ®ï¼ˆä¼šè‡ªåŠ¨æ£€æµ‹æ–‡ä»¶æ ¼å¼ï¼‰
dw.preload_data(start_date="20230101", end_date="20241231", lookback_days=120)

# è·å–äº¤æ˜“æ—¥å†ï¼ˆç›´æ¥ä»å†…å­˜æŸ¥è¯¢ï¼Œéå¸¸å¿«ï¼‰
trade_days = dw.get_trade_days("20230101", "20241231")

# è·å–è‚¡ç¥¨æ•°æ®ï¼ˆåŒ…å« pct_chg, pre_closeï¼‰
stock_data = dw.get_stock_data("000001.SZ", end_date="20241231", days=120)

# è·å–æœªæ¥æ•°æ®ï¼ˆåŒ…å« pct_chg, pre_closeï¼‰
future_data = dw.get_future_data("000001.SZ", current_date="20241231", days=5)

# è·å–å½“æ—¥å…¨å¸‚åœºæ•°æ®
daily_data = dw.load_daily_data("20241231")
```

## æ³¨æ„äº‹é¡¹

1. **æ¨èæ•°æ®æ ¼å¼**ï¼š
   - æŒ‰æ—¥æœŸå­˜å‚¨ï¼ˆæ¨èï¼‰ï¼š`data/daily/20230101.csv`
   - æŒ‰è‚¡ç¥¨å­˜å‚¨ï¼ˆå…¼å®¹ï¼‰ï¼š`data/daily/000001.SZ.csv`ï¼ˆè¾ƒæ…¢ï¼‰

2. **å­—æ®µè¦æ±‚**ï¼š
   - å¿…é¡»åŒ…å«ï¼š`ts_code`, `trade_date`, `open`, `high`, `low`, `close`, `vol`, `amount`, `pct_chg`, `pre_close`
   - å¯é€‰ï¼š`adj_factor`ï¼ˆå¤æƒå› å­ï¼‰

3. **å†…å­˜è¦æ±‚**ï¼š
   - å»ºè®® 8GB+ å†…å­˜
   - 2023-2024 å…¨å¸‚åœºæ•°æ®çº¦å ç”¨ 70MB

4. **å»é‡é€»è¾‘**ï¼š
   - åŸºäº `ts_code` å’Œ `trade_date` å»é‡
   - å¦‚æœæœ‰é‡å¤è®°å½•ï¼Œä¿ç•™æœ€åä¸€æ¡

## æµ‹è¯•éªŒè¯

```bash
# åŸºæœ¬å¯¼å…¥æµ‹è¯•
python -c "from data_warehouse_turbo import DataWarehouseTurbo; print('å¯¼å…¥æˆåŠŸ')"

# å®Œæ•´æµ‹è¯•
python train_final.py --start 20230101 --end 20240115 --dry-run
```

## ç›¸å…³æ–‡ä»¶

- `data_warehouse_turbo.py` - æœ€ç»ˆä¿®æ­£ç‰ˆï¼ˆæœ¬æ–‡æ¡£ï¼‰
- `train_final.py` - æ¨èçš„è®­ç»ƒè„šæœ¬ï¼ˆå·²é›†æˆ Turbo æ¨¡å¼ï¼‰
- `ai_referee.py` - AI è£åˆ¤ï¼ˆéœ€è¦ pct_chg å­—æ®µè®¡ç®—æ ‡ç­¾ï¼‰
- `feature_extractor.py` - ç‰¹å¾æå–å™¨ï¼ˆå¯èƒ½éœ€è¦ pre_close å­—æ®µï¼‰

## ç‰ˆæœ¬å†å²

- **V1** (2024-12-20): åˆå§‹ç‰ˆæœ¬ï¼Œå®ç°å…¨é‡é¢„åŠ è½½ + å¤åˆç´¢å¼•
- **V2** (2024-12-23): æœ€ç»ˆä¿®æ­£ç‰ˆ
  - âœ… å¢åŠ  pct_chg, pre_close å­—æ®µ
  - âœ… æ™ºèƒ½æ–‡ä»¶æ ¼å¼æ£€æµ‹
  - âœ… ä¼˜åŒ– get_trade_days æ–¹æ³•
  - âœ… å¢åŠ å»é‡å¤„ç†

---

**ä½œè€…**: Coze Coding
**æ›´æ–°**: 2024-12-23
**çŠ¶æ€**: âœ… å·²éªŒè¯
