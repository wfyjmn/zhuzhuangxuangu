# -*- coding: utf-8 -*-
"""
å®Œæ•´è®­ç»ƒæµç¨‹ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º
ç”±äºçœŸå®æ•°æ®ç”Ÿæˆé€Ÿåº¦å¤ªæ…¢ï¼ˆçº¦23ç§’/è‚¡ç¥¨ï¼‰ï¼Œè¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºå®Œæ•´æµç¨‹
"""

import pandas as pd
import numpy as np
import os
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from ai_referee import AIReferee


def generate_mock_data(n_samples=1000):
    """ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®"""
    print("="*80)
    print("ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®")
    print("="*80 + "\n")

    np.random.seed(42)

    # ç”Ÿæˆ 22 ä¸ªç‰¹å¾
    feature_names = [
        'vol_ratio', 'turnover_rate', 'pe_ttm',
        'pct_chg_1d', 'pct_chg_5d', 'pct_chg_20d',
        'ma5_slope', 'ma20_slope',
        'bias_5', 'bias_20',
        'rsi_14', 'std_20_ratio',
        'position_20d', 'position_250d',
        'macd_dif', 'macd_dea', 'macd_hist',
        'index_pct_chg', 'sector_pct_chg',
        'moneyflow_score', 'tech_score'
    ]

    data = {}

    for feature in feature_names:
        if 'ratio' in feature or 'pct' in feature:
            data[feature] = np.random.randn(n_samples) * 0.5 + 1.0
        elif feature in ['rsi_14', 'position_20d', 'position_250d']:
            data[feature] = np.random.rand(n_samples) * 100
        elif 'score' in feature:
            data[feature] = np.random.rand(n_samples) * 100
        else:
            data[feature] = np.random.randn(n_samples)

    # ç”Ÿæˆæ ‡ç­¾ï¼ˆ15% æ­£æ ·æœ¬ï¼‰
    labels = np.random.choice([0, 1], size=n_samples, p=[0.85, 0.15])

    df = pd.DataFrame(data)
    df['label'] = labels

    # æ·»åŠ  ts_code å’Œ trade_dateï¼ˆä»…ç”¨äºæ ‡è¯†ï¼‰
    df['ts_code'] = [f'60{i:04d}.SH' for i in range(n_samples)]
    df['trade_date'] = np.random.choice(['20240102', '20240103', '20240104', '20240105'], n_samples)

    print(f"âœ… ç”Ÿæˆ {n_samples} æ¡æ¨¡æ‹Ÿæ•°æ®")
    print(f"  æ­£æ ·æœ¬: {labels.sum()} ({labels.sum()/n_samples*100:.1f}%)")
    print(f"  è´Ÿæ ·æœ¬: {n_samples - labels.sum()} ({(1-labels.sum()/n_samples)*100:.1f}%)")
    print(f"  ç‰¹å¾æ•°: {len(feature_names)}\n")

    return df


def full_training_pipeline():
    """å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰"""
    print("="*80)
    print(" " * 25 + "DeepQuant å®Œæ•´è®­ç»ƒæµç¨‹")
    print(" " * 28 + "ï¼ˆæ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºï¼‰")
    print("="*80 + "\n")

    # æ­¥éª¤ 1ï¼šç”Ÿæˆè®­ç»ƒæ•°æ®
    print("ã€æ­¥éª¤ 1ã€‘ç”Ÿæˆè®­ç»ƒæ•°æ®")
    print("="*80 + "\n")

    df = generate_mock_data(n_samples=5000)

    # ä¿å­˜æ•°æ®
    output_dir = "data/training"
    os.makedirs(output_dir, exist_ok=True)

    data_file = os.path.join(output_dir, "mock_training_data.csv")
    df.to_csv(data_file, index=False)
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜ï¼š{data_file}\n")

    # æ­¥éª¤ 2ï¼šè®­ç»ƒæ¨¡å‹
    print("\n" + "="*80)
    print("ã€æ­¥éª¤ 2ã€‘è®­ç»ƒ AI è£åˆ¤æ¨¡å‹")
    print("="*80 + "\n")

    feature_cols = [col for col in df.columns if col not in ['label', 'ts_code', 'trade_date']]
    X = df[feature_cols]
    y = df['label']

    # ä¿ç•™ trade_date åˆ—ç”¨äºæ—¶åºäº¤å‰éªŒè¯
    X_with_date = X.copy()
    X_with_date['trade_date'] = df['trade_date']

    print(f"ç‰¹å¾æ•°: {len(feature_cols)}")
    print(f"è®­ç»ƒæ ·æœ¬: {len(X)}")
    print(f"æ­£æ ·æœ¬: {y.sum()} ({y.sum()/len(y)*100:.1f}%)")
    print(f"è´Ÿæ ·æœ¬: {len(y) - y.sum()} ({(1-y.sum()/len(y))*100:.1f}%)\n")

    # åˆå§‹åŒ–æ¨¡å‹
    print("åˆå§‹åŒ– XGBoost æ¨¡å‹...")
    referee = AIReferee(model_type='xgboost')

    start_time = datetime.now()

    # è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨æ—¶åºäº¤å‰éªŒè¯ï¼‰
    print("å¼€å§‹è®­ç»ƒï¼ˆæ—¶åºäº¤å‰éªŒè¯ï¼Œ5æŠ˜ï¼‰...")
    referee.train_time_series(X_with_date, y, n_splits=5)

    duration = (datetime.now() - start_time).total_seconds()

    print(f"\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼ç”¨æ—¶: {duration/60:.1f} åˆ†é’Ÿ")

    # ä¿å­˜æ¨¡å‹
    model_file = os.path.join(output_dir, "ai_referee_model.pkl")
    referee.save_model(model_file)
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ï¼š{model_file}\n")

    # æ­¥éª¤ 3ï¼šè¯„ä¼°æ¨¡å‹
    print("\n" + "="*80)
    print("ã€æ­¥éª¤ 3ã€‘è¯„ä¼°æ¨¡å‹")
    print("="*80 + "\n")

    y_pred = referee.model.predict(X)
    y_prob = referee.model.predict_proba(X)[:, 1]

    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report

    accuracy = accuracy_score(y, y_pred)
    precision = precision_score(y, y_pred, zero_division=0)
    recall = recall_score(y, y_pred, zero_division=0)
    f1 = f1_score(y, y_pred, zero_division=0)
    auc = roc_auc_score(y, y_prob)

    print("è®­ç»ƒé›†è¯„ä¼°æŒ‡æ ‡ï¼š")
    print(f"  å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰: {accuracy:.4f}")
    print(f"  ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰: {precision:.4f}")
    print(f"  å¬å›ç‡ï¼ˆRecallï¼‰: {recall:.4f}")
    print(f"  F1åˆ†æ•°: {f1:.4f}")
    print(f"  AUCåˆ†æ•°: {auc:.4f}")

    print("\næ··æ·†çŸ©é˜µï¼š")
    cm = confusion_matrix(y, y_pred)
    print(f"  é¢„æµ‹è´Ÿæ ·æœ¬: TN={cm[0,0]}, FP={cm[0,1]}")
    print(f"  é¢„æµ‹æ­£æ ·æœ¬: FN={cm[1,0]}, TP={cm[1,1]}")

    print("\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Šï¼š")
    print(classification_report(y, y_pred, digits=4))

    # æ˜¾ç¤ºé¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
    print("\né¢„æµ‹æ¦‚ç‡åˆ†å¸ƒï¼š")
    print(f"  å¹³å‡æ¦‚ç‡: {y_prob.mean():.4f}")
    print(f"  æ­£æ ·æœ¬æ¦‚ç‡: {y_prob[y==1].mean():.4f}")
    print(f"  è´Ÿæ ·æœ¬æ¦‚ç‡: {y_prob[y==0].mean():.4f}")
    print(f"  æ¦‚ç‡ä¸­ä½æ•°: {np.median(y_prob):.4f}")

    # ç‰¹å¾é‡è¦æ€§
    print("\n" + "="*80)
    print("ç‰¹å¾é‡è¦æ€§ï¼ˆTop 10ï¼‰")
    print("="*80 + "\n")

    # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ç‰¹å¾é‡è¦æ€§è®¡ç®—æ–¹å¼
    if hasattr(referee.model, 'feature_importances_'):
        # æ ‘æ¨¡å‹ï¼ˆXGBoost, LightGBMï¼‰
        importances = referee.model.feature_importances_
    elif hasattr(referee.model, 'coef_'):
        # çº¿æ€§æ¨¡å‹ï¼ˆLogisticRegressionï¼‰
        importances = np.abs(referee.model.coef_[0])
    else:
        print("  [è­¦å‘Š] å½“å‰æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ")
        importances = np.zeros(len(feature_cols))

    feature_importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': importances
    }).sort_values('importance', ascending=False)

    if importances.sum() > 0:
        print(feature_importance.head(10).to_string(index=False))
    else:
        print("  æ¨¡å‹ä¸æä¾›ç‰¹å¾é‡è¦æ€§")

    print("\n" + "="*80)
    print("âœ… å®Œæ•´è®­ç»ƒæµç¨‹å®Œæˆï¼")
    print("="*80 + "\n")

    print("ä½¿ç”¨è¯´æ˜ï¼š")
    print("  1. è®­ç»ƒæ•°æ®å·²ä¿å­˜ï¼šdata/training/mock_training_data.csv")
    print("  2. æ¨¡å‹å·²ä¿å­˜ï¼šdata/training/ai_referee_model.pkl")
    print("  3. å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç åŠ è½½æ¨¡å‹ï¼š")
    print("     from ai_referee import AIReferee")
    print("     referee = AIReferee()")
    print("     referee.load_model('data/training/ai_referee_model.pkl')")
    print("\n")


if __name__ == "__main__":
    try:
        full_training_pipeline()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµç¨‹è¢«ç”¨æˆ·ä¸­æ–­\n")
    except Exception as e:
        print(f"\n\nâŒ æµç¨‹å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
