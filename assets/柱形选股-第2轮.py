# -*- coding: utf-8 -*-
"""
DeepQuant Pro V2.1 - ç»ˆæä¿®å¤ç‰ˆ
ä¿®å¤ï¼š
1. æ•´åˆäº†é«˜æ•ˆçš„æ•°æ®è·å–æ¨¡å— (efficient_fetch_stock_data)
2. æ•´åˆäº†è¯„åˆ†é‡ç®—æ¨¡å— (calculate_score)
3. æ•´åˆäº†é£æ§åŒè½¨åˆ¶ (ä¿æŠ¤ç¼©é‡æ´—ç›˜)
æ›´æ–°ï¼šæ”¯æŒä»é…ç½®æ–‡ä»¶è¯»å–å‚æ•°
"""

import tushare as ts
from config import TUSHARE_TOKEN
import pandas as pd
import numpy as np
import time
import datetime
import os
import re
import json
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed

# ================= é…ç½®åŒºåŸŸ =================


# å‚æ•°é…ç½®æ–‡ä»¶
PARAMS_FILE = 'strategy_params.json'

# é»˜è®¤å‚æ•°ï¼ˆå¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶ä½¿ç”¨ï¼‰
DEFAULT_PARAMS = {
    'SCORE_THRESHOLD_NORMAL': 55,
    'SCORE_THRESHOLD_WASH': 45,
    'TURNOVER_THRESHOLD_NORMAL': 1.5,
    'TURNOVER_THRESHOLD_WASH': 0.6,
    'TOP_N_PER_STRATEGY': 5
}

# ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°
def load_params():
    """åŠ è½½å‚æ•°é…ç½®"""
    if os.path.exists(PARAMS_FILE):
        try:
            with open(PARAMS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                second_round = data.get('params', {}).get('second_round', {})
                return {
                    'SCORE_THRESHOLD_NORMAL': second_round.get('SCORE_THRESHOLD_NORMAL', 55),
                    'SCORE_THRESHOLD_WASH': second_round.get('SCORE_THRESHOLD_WASH', 45),
                    'TURNOVER_THRESHOLD_NORMAL': second_round.get('TURNOVER_THRESHOLD_NORMAL', 1.5),
                    'TURNOVER_THRESHOLD_WASH': second_round.get('TURNOVER_THRESHOLD_WASH', 0.6),
                    'TOP_N_PER_STRATEGY': second_round.get('TOP_N_PER_STRATEGY', 5)
                }
        except Exception as e:
            print(f"[è­¦å‘Š] åŠ è½½å‚æ•°é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°: {e}")
    return DEFAULT_PARAMS

# åŠ è½½å‚æ•°
PARAMS = load_params()
SCORE_THRESHOLD_NORMAL = PARAMS['SCORE_THRESHOLD_NORMAL']
SCORE_THRESHOLD_WASH = PARAMS['SCORE_THRESHOLD_WASH']
TURNOVER_THRESHOLD_NORMAL = PARAMS['TURNOVER_THRESHOLD_NORMAL']
TURNOVER_THRESHOLD_WASH = PARAMS['TURNOVER_THRESHOLD_WASH']
TOP_N_PER_STRATEGY = PARAMS['TOP_N_PER_STRATEGY']

print(f"[ç³»ç»Ÿ] åŠ è½½å‚æ•°: SCORE_NORMAL={SCORE_THRESHOLD_NORMAL}, SCORE_WASH={SCORE_THRESHOLD_WASH}")

# åŠ¨æ€ç”Ÿæˆè¾“å…¥æ–‡ä»¶å
def get_input_file(target_date):
    """ç”Ÿæˆè¾“å…¥æ–‡ä»¶å"""
    return f'Best_Pick_{target_date}.csv'

# ===========================================

ts.set_token(TUSHARE_TOKEN)
pro = ts.pro_api(timeout=30)


def get_trade_context():
    try:
        now_date = datetime.datetime.now().strftime('%Y%m%d')
        cal_df = pro.trade_cal(exchange='', start_date='20200101', end_date=now_date, is_open='1')
        cal_df = cal_df.sort_values('cal_date', ascending=True).reset_index(drop=True)
        last_trade_day = cal_df['cal_date'].values[-1]

        # è®¡ç®—å›æº¯èµ·å§‹æ—¥ (ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—å‡çº¿)
        start_date_idx = max(0, len(cal_df) - 400)
        start_date = cal_df['cal_date'].values[start_date_idx]

        print(f"[ç³»ç»Ÿ] è¡Œæƒ…æ•°æ®æˆªæ­¢æ—¥: {last_trade_day}")
        return last_trade_day, start_date
    except:
        return None, None


def load_candidate_pool(filename):
    if not os.path.exists(filename):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {filename}")
        return pd.DataFrame()
    try:
        df = pd.read_csv(filename, encoding='utf-8-sig')
    except:
        try:
            df = pd.read_csv(filename, encoding='gbk')
        except:
            return pd.DataFrame()
    return df


def get_daily_data_batch(codes, start_date, end_date):
    """è·å–æ—¥çº¿è¡Œæƒ…"""
    try:
        df = pro.daily(ts_code=",".join(codes), start_date=start_date, end_date=end_date)
        return df
    except:
        return pd.DataFrame()


# ==============================================================================
# æ¨¡å—1: è¯„åˆ†é‡ç®— (Core)
# ==============================================================================
def calculate_score(strategy, df_daily):
    if len(df_daily) < 60: return 0, 0, 0, 0, 0

    curr = df_daily.iloc[-1]
    prev = df_daily.iloc[-2]

    close = curr['close']
    pct_chg = curr['pct_chg']

    ma20 = df_daily['close'].rolling(20).mean().iloc[-1]
    ma60 = df_daily['close'].rolling(60).mean().iloc[-1]

    vol_ma5 = df_daily['vol'].rolling(5).mean().iloc[-1]
    vol_ratio = curr['vol'] / vol_ma5 if vol_ma5 > 0 else 0
    vol_prev = curr['vol'] / prev['vol'] if prev['vol'] > 0 else 0

    high_250 = df_daily['high'].iloc[-250:].max()
    low_250 = df_daily['low'].iloc[-250:].min()
    pos_ratio = (close - low_250) / (high_250 - low_250) if high_250 != low_250 else 0.5

    # 1. å®‰å…¨æ€§
    if pos_ratio <= 0.2:
        base_safe = 25
    elif pos_ratio <= 0.4:
        base_safe = 20
    elif pos_ratio <= 0.6:
        base_safe = 15
    else:
        base_safe = 10
    if vol_ratio < 0.8: base_safe += 2
    s_safe = min(25, base_safe)

    # 2. è¿›æ”»æ€§ (ä¿®æ­£ï¼šç»™æ´—ç›˜ç­–ç•¥è¡¥å¿)
    s_off = 0
    if "å¼ºæ”»" in str(strategy):
        s_off += 15
    elif "æ¢¯é‡" in str(strategy):
        s_off += 10
    elif "æ´—ç›˜" in str(strategy):
        s_off += 5

    if vol_ratio > 2.0:
        s_off += 10
    elif vol_ratio > 1.5:
        s_off += 8

    if pct_chg > 5:
        s_off += 10
    elif pct_chg > 2:
        s_off += 5

    # [å…³é”®] ç¼©é‡æ´—ç›˜è¡¥å¿åˆ†
    if "æ´—ç›˜" in str(strategy) and -3 < pct_chg < 3:
        s_off += 10

    s_off = min(35, s_off)

    # 3. ç¡®å®šæ€§
    s_cert = 10
    if vol_prev > 1.8: s_cert += 5
    if close > ma20 and close > ma60: s_cert += 10
    s_cert = min(25, s_cert)

    # 4. é…åˆåº¦
    s_match = 10
    if pos_ratio < 0.3 and vol_ratio > 1.5 and pct_chg > 0: s_match += 5
    if pos_ratio < 0.6 and vol_ratio < 0.8 and -3 < pct_chg < 0: s_match += 5
    s_match = min(15, s_match)

    total = s_safe + s_off + s_cert + s_match
    return total, s_safe, s_off, s_cert, s_match


# ==============================================================================
# æ¨¡å—2: é«˜æ•ˆæ•°æ®è·å– (Robust Fetcher)
# ==============================================================================
def fetch_single_stock_basic(ts_code, target_date, max_retries=3):
    """å•åªè‚¡ç¥¨åŸºæœ¬é¢è·å–ï¼Œå¸¦æ™ºèƒ½å›æº¯"""
    # å°è¯•å›æº¯ 5 å¤©ï¼Œç¡®ä¿æ‹¿åˆ°æ•°æ®
    for day_lag in range(5):
        try:
            curr_date = (datetime.datetime.strptime(target_date, '%Y%m%d') - datetime.timedelta(days=day_lag)).strftime(
                '%Y%m%d')

            # é‡è¯•æœºåˆ¶
            for attempt in range(max_retries):
                try:
                    df = pro.daily_basic(ts_code=ts_code, trade_date=curr_date,
                                         fields='ts_code,pe_ttm,turnover_rate,circ_mv')
                    if not df.empty:
                        return df.iloc[0].to_dict()  # æˆåŠŸè¿”å›
                    break  # å¦‚æœæ—¥æœŸä¸å¯¹ï¼Œæ²¡å¿…è¦é‡è¯•APIï¼Œç›´æ¥æ¢æ—¥æœŸ
                except:
                    time.sleep(0.5)
        except:
            pass
    return None


def efficient_fetch_stock_data(codes, target_date):
    """å¤šçº¿ç¨‹æ‰¹é‡è·å–"""
    print(f"    å¯åŠ¨å¤šçº¿ç¨‹è·å– {len(codes)} åªè‚¡ç¥¨çš„åŸºæœ¬é¢ (æ™ºèƒ½å›æº¯)...")
    results = []

    # çº¿ç¨‹æ•°ä¸å®œè¿‡å¤šï¼Œé˜²æ­¢Tushareå°IP
    with ThreadPoolExecutor(max_workers=8) as executor:
        future_to_code = {executor.submit(fetch_single_stock_basic, code, target_date): code for code in codes}

        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
        for future in tqdm(as_completed(future_to_code), total=len(codes), desc="    è·å–è¿›åº¦"):
            res = future.result()
            if res:
                results.append(res)

    return pd.DataFrame(results)


# ==============================================================================
# ä¸»æµç¨‹
# ==============================================================================
def run_system():
    print("=" * 60)
    print("   DeepQuant Pro V2.1 - ç»ˆæä¿®å¤ç‰ˆ")
    print("=" * 60)

    # 1. å‡†å¤‡
    target_date, start_date = get_trade_context()
    if not target_date: return

    # åŠ¨æ€ç”Ÿæˆè¾“å…¥æ–‡ä»¶å
    input_file = get_input_file(target_date)
    df_pool = load_candidate_pool(input_file)
    if df_pool.empty:
        print(f"[é”™è¯¯] æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {input_file}")
        return

    stock_list = df_pool['ts_code'].tolist()
    print(f"[1] å€™é€‰æ± : {len(stock_list)} åª")

    strategy_map = df_pool.set_index('ts_code')['strategy'].to_dict()

    # 2. é‡æ–°è®¡ç®—è¯„åˆ†
    print(f"[2] é‡æ–°è®¡ç®—è¯„åˆ†...")
    scored_results = []

    batch_size = 50
    # ç®€å•çš„æ‰¹å¤„ç†è·å–æ—¥çº¿
    for i in tqdm(range(0, len(stock_list), batch_size), desc="    æ—¥çº¿åˆ†æ"):
        batch_codes = stock_list[i:i + batch_size]
        df_daily = get_daily_data_batch(batch_codes, start_date, target_date)

        if not df_daily.empty:
            groups = df_daily.groupby('ts_code')
            for code in batch_codes:
                if code in groups.groups:
                    sub_df = groups.get_group(code).sort_values('trade_date')
                    strategy = strategy_map.get(code, "æœªçŸ¥")

                    total, s_safe, s_off, s_cert, s_match = calculate_score(strategy, sub_df)
                    curr = sub_df.iloc[-1]

                    scored_results.append({
                        'ts_code': code,
                        'strategy': strategy,
                        'New_Score': total,
                        'S_Safe': s_safe,
                        'close': curr['close'],
                        'pct_chg': curr['pct_chg']
                    })
        time.sleep(0.1)

    df_scored = pd.DataFrame(scored_results)
    print(f"    è¯„åˆ†å®Œæˆï¼Œæœ‰æ•ˆ: {len(df_scored)} æ¡")

    # 3. è·å–åŸºæœ¬é¢ (ä½¿ç”¨é«˜æ•ˆæ¨¡å—)
    print(f"[3] è·å–åŸºæœ¬é¢æ•°æ®...")
    df_basic = efficient_fetch_stock_data(df_scored['ts_code'].tolist(), target_date)

    if df_basic.empty:
        print("    ä¸¥é‡é”™è¯¯ï¼šæ— æ³•è·å–ä»»ä½•åŸºæœ¬é¢æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–Tokenæƒé™ã€‚")
        # å…œåº•ï¼šå¦‚æœæ²¡æœ‰åŸºæœ¬é¢ï¼Œå°±ä¸å¡åŸºæœ¬é¢äº†ï¼Œåªå¡æŠ€æœ¯åˆ†
        print("    [åº”æ€¥æ¨¡å¼] ä»…ä½¿ç”¨æŠ€æœ¯è¯„åˆ†è¿›è¡Œç­›é€‰...")
        df_final = df_scored.copy()
        df_final['pe_ttm'] = -1
        df_final['turnover_rate'] = -1
        df_final['circ_mv'] = -1
    else:
        df_final = pd.merge(df_scored, df_basic, on='ts_code', how='inner')

    # 4. é£æ§ç­›é€‰ (åŒè½¨åˆ¶)
    print(f"[4] æ‰§è¡Œé£æ§ç­›é€‰...")

    # åŸºç¡€æ¡ä»¶ (å¦‚æœæœ‰åŸºæœ¬é¢æ•°æ®æ‰å¡)
    cond_pe = (df_final['pe_ttm'] > 0) & (df_final['pe_ttm'] < 100) if 'pe_ttm' in df_final.columns and df_final[
        'pe_ttm'].max() > 0 else True
    # å¸‚å€¼ > 20äº¿ (200000ä¸‡å…ƒ)
    cond_mv = (df_final['circ_mv'] > 200000) if 'circ_mv' in df_final.columns and df_final[
        'circ_mv'].max() > 0 else True

    # è¯„åˆ†ä¸æ¢æ‰‹ç‡åŒè½¨åˆ¶
    is_wash = df_final['strategy'].str.contains("æ´—ç›˜")

    # åˆ†æ•°çº¿ï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°ï¼‰
    cond_score_normal = (df_final['New_Score'] >= SCORE_THRESHOLD_NORMAL) & (~is_wash)
    cond_score_wash = (df_final['New_Score'] >= SCORE_THRESHOLD_WASH) & (is_wash)
    cond_score = cond_score_normal | cond_score_wash

    # æ¢æ‰‹ç‡ (å¦‚æœæœ‰æ•°æ®ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°)
    if 'turnover_rate' in df_final.columns and df_final['turnover_rate'].max() > 0:
        cond_to_normal = (df_final['turnover_rate'] > TURNOVER_THRESHOLD_NORMAL) & (~is_wash)
        cond_to_wash = (df_final['turnover_rate'] > TURNOVER_THRESHOLD_WASH) & (is_wash)
        cond_to = cond_to_normal | cond_to_wash
    else:
        cond_to = True

    df_pass = df_final[cond_pe & cond_mv & cond_to & cond_score].copy()

    print(f"    é£æ§åˆç­›ç»“æœ: {len(df_pass)} åª")
    
    # ==========================================================================
    # [æ–°å¢] ç»ˆæPKï¼šæ¯ç§ç­–ç•¥åªå– Top 3-5
    # ==========================================================================
    print(f"[5] æ‰§è¡Œç»ˆæPK (ä¼˜ä¸­é€‰ä¼˜)...")
    
    final_picks = []
    
    # 1. å¤„ç†ã€â˜…ä½ä½å¼ºæ”»ã€‘
    # æ’åºé€»è¾‘ï¼šä¼˜å…ˆçœ‹æ€»åˆ†(New_Score)ï¼Œå…¶æ¬¡çœ‹æ¶¨å¹…(pct_chg)
    # å¼ºæ”»å°±è¦é€‰æœ€å¼ºçš„
    df_attack = df_pass[df_pass['strategy'].str.contains("å¼ºæ”»")].copy()
    if not df_attack.empty:
        df_attack = df_attack.sort_values(by=['New_Score', 'pct_chg'], ascending=[False, False])
        top_attack = df_attack.head(TOP_N_PER_STRATEGY) # å–å‰Nå¤‡é€‰
        final_picks.append(top_attack)
        print(f"    â˜…ä½ä½å¼ºæ”»: å…¥å›´ {len(df_attack)} -> ç²¾é€‰ {len(top_attack)}")

    # 2. å¤„ç†ã€â˜†ç¼©é‡æ´—ç›˜ã€‘
    # æ’åºé€»è¾‘ï¼šä¼˜å…ˆçœ‹æ€»åˆ†ï¼Œå…¶æ¬¡çœ‹é‡æ¯”(vol_ratio)è¶Šå°è¶Šå¥½(æ´—å¾—å¹²å‡€)
    # æˆ‘ä»¬éœ€è¦å…ˆè®¡ç®— vol_ratio (å¦‚æœdf_passé‡Œæ²¡æœ‰ï¼Œéœ€è¦ä»df_scoredé‡Œæ‹¿ï¼Œæˆ–è€…ç®€å•ç”¨S_Safeä»£æ›¿)
    # è¿™é‡Œçš„ New_Score å·²ç»åŒ…å«äº†å¯¹ç¼©é‡çš„åŠ åˆ†ï¼Œç›´æ¥ç”¨ New_Score æ’åºå³å¯
    df_wash = df_pass[df_pass['strategy'].str.contains("æ´—ç›˜")].copy()
    if not df_wash.empty:
        # æ´—ç›˜è‚¡ï¼šåˆ†æ•°é«˜è¯´æ˜ä½ç½®å¥½ã€æ”¯æ’‘å¼ºï¼›é‡æ¯”ä½è¯´æ˜æ´—å¾—å¹²å‡€
        # è¿™é‡Œæˆ‘ä»¬ç®€å•æŒ‰æ€»åˆ†æ’åº
        df_wash = df_wash.sort_values(by=['New_Score'], ascending=False)
        top_wash = df_wash.head(TOP_N_PER_STRATEGY)
        final_picks.append(top_wash)
        print(f"    â˜†ç¼©é‡æ´—ç›˜: å…¥å›´ {len(df_wash)} -> ç²¾é€‰ {len(top_wash)}")

    # 3. å¤„ç†ã€â–²æ¢¯é‡ä¸Šè¡Œã€‘
    # æ’åºé€»è¾‘ï¼šæŒ‰æ€»åˆ†
    df_ladder = df_pass[df_pass['strategy'].str.contains("æ¢¯é‡")].copy()
    if not df_ladder.empty:
        df_ladder = df_ladder.sort_values(by=['New_Score'], ascending=False)
        top_ladder = df_ladder.head(TOP_N_PER_STRATEGY)
        final_picks.append(top_ladder)
        print(f"    â–²æ¢¯é‡ä¸Šè¡Œ: å…¥å›´ {len(df_ladder)} -> ç²¾é€‰ {len(top_ladder)}")

    # åˆå¹¶ç»“æœ
    if not final_picks:
        print("    é—æ†¾ï¼Œæ²¡æœ‰è‚¡ç¥¨é€šè¿‡ç»ˆæPKã€‚")
        return

    df_final_top = pd.concat(final_picks)
    
    # 4. è¡¥å……åç§°å’Œä»“ä½å»ºè®® (å¯¹ç²¾é€‰è‚¡è¿›è¡Œ)
    try:
        names = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,industry')
        df_final_top = pd.merge(df_final_top, names, on='ts_code', how='left')
    except: pass
    
    def get_pos_sugg(row):
        safe = row['S_Safe']
        # åŠ¨æ€ä»“ä½ï¼šå¦‚æœæ˜¯Top1ï¼Œä»“ä½åŠ æˆ
        base_pos = 10
        if safe >= 20: base_pos += 2
        elif safe < 15: base_pos -= 2
        return f"{base_pos}%"
    
    df_final_top['Pos_Sugg'] = df_final_top.apply(get_pos_sugg, axis=1)
    
    # è½¬æ¢å•ä½
    if 'circ_mv' in df_final_top.columns:
        df_final_top['MV_Yi'] = round(df_final_top['circ_mv'] / 10000, 2)
    
    # æ•´ç†è¾“å‡º
    cols = ['ts_code', 'name', 'industry', 'strategy', 'New_Score', 'Pos_Sugg', 'close', 'pct_chg', 'pe_ttm', 'turnover_rate', 'MV_Yi']
    # ä»…ä¿ç•™å­˜åœ¨çš„åˆ—
    final_cols = [c for c in cols if c in df_final_top.columns]
    
    df_final_top = df_final_top[final_cols].sort_values(['strategy', 'New_Score'], ascending=[True, False])
    
    outfile = f'DeepQuant_TopPicks_{target_date}.csv'
    df_final_top.to_csv(outfile, index=False, encoding='utf-8-sig')
    
    print("\n" + "="*80)
    print("ã€ğŸ‘‘ çš‡å®¶ç²¾é€‰ Top 15ã€‘")
    print("è¯´æ˜ï¼šæ¯ä¸ªç­–ç•¥èµ›é“ä»…å±•ç¤ºå‰ 5 åï¼Œå»ºè®®é‡ç‚¹å…³æ³¨å‰ 3 åã€‚")
    print("="*80)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 1000)
    print(df_final_top)
    print(f"\nç»“æœå·²ä¿å­˜: {outfile}")

if __name__ == '__main__':
    run_system()