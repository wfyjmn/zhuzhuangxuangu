#!/bin/bash
# æµ‹è¯•å¢é‡æ›´æ–°åŠŸèƒ½ï¼ˆä»…æµ‹è¯• 10 å¤©ï¼‰

# 1. ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
cd /workspace/projects || exit

# 2. åŠ è½½ç¯å¢ƒå˜é‡
if [ -f .env ]; then
    export $(cat .env | grep -v '^#' | xargs)
    echo "âœ… ç¯å¢ƒå˜é‡å·²åŠ è½½"
else
    echo "âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ° .env æ–‡ä»¶"
fi

echo ""
echo "ğŸ§ª å¯åŠ¨å¢é‡æ›´æ–°æµ‹è¯•..."
echo "ğŸ“… æµ‹è¯•èŒƒå›´: 2024.01.01 ~ 2024.01.10 (10 å¤©)"

python3 -u -c "
import os
import sys
import time
from pathlib import Path

# ç¡®ä¿èƒ½å¯¼å…¥é¡¹ç›®æ ¹ç›®å½•çš„æ¨¡å—
project_root = Path.cwd()
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'assets'))

try:
    from data_warehouse import DataWarehouse
    import tushare as ts
except ImportError as e:
    print(f'âŒ å¯¼å…¥å¤±è´¥: {e}')
    print(f'å½“å‰è·¯å¾„: {os.getcwd()}')
    sys.exit(1)

print('=' * 80)
print('ğŸ§ª å¢é‡æ›´æ–°åŠŸèƒ½æµ‹è¯•')
print('=' * 80)

dw = DataWarehouse()
pro = ts.pro_api()

# ------------------------------------------------------------------
# ä»»åŠ¡ 1: ä¸‹è½½ä¸Šè¯æŒ‡æ•°æµ‹è¯•
# ------------------------------------------------------------------
print('\n[æµ‹è¯• 1/2] ä¸‹è½½ä¸Šè¯æŒ‡æ•° (000001.SH)...')
try:
    df_index = pro.index_daily(ts_code='000001.SH', start_date='20240101', end_date='20240110')
    if not df_index.empty:
        save_path = project_root / 'assets' / 'data' / 'daily' / '000001.SH.csv'
        save_path.parent.mkdir(parents=True, exist_ok=True)
        df_index.sort_values('trade_date', inplace=True)
        df_index.to_csv(save_path, index=False)
        print(f'  âœ… æŒ‡æ•°æ•°æ®å·²ä¿å­˜: {save_path} ({len(df_index)} æ¡)')
        print(f'  ğŸ“Š åŒ…å«å­—æ®µ: {list(df_index.columns)}')
    else:
        print('  âš ï¸  æœªè·å–åˆ°æŒ‡æ•°æ•°æ®')
except Exception as e:
    print(f'  âŒ æŒ‡æ•°ä¸‹è½½å¤±è´¥: {e}')

# ------------------------------------------------------------------
# ä»»åŠ¡ 2: ä¸‹è½½ä¸ªè‚¡æ•°æ®æµ‹è¯•
# ------------------------------------------------------------------
print('\n[æµ‹è¯• 2/2] ä¸‹è½½ä¸ªè‚¡æ•°æ® (2024.01.01 ~ 2024.01.10)...')

test_dates = ['20240101', '20240102', '20240103', '20240104', '20240105',
              '20240108', '20240109', '20240110']

print(f'æµ‹è¯•å¤©æ•°: {len(test_dates)} å¤©')

success_count = 0

for i, date in enumerate(test_dates, 1):
    try:
        df = dw.download_daily_data(date, force=True)

        if df is not None:
            has_turnover = 'turnover_rate' in df.columns
            has_pe = 'pe_ttm' in df.columns
            has_pb = 'pb' in df.columns

            status = 'âœ…' if (has_turnover and has_pe and has_pb) else 'âš ï¸ '
            print(f'  {status} [{i}/{len(test_dates)}] {date} - '
                  f'Turnover: {has_turnover}, PE: {has_pe}, PB: {has_pb}')

            if has_turnover and has_pe:
                success_count += 1
        else:
            print(f'  âŒ [{i}/{len(test_dates)}] {date} - ä¸‹è½½å¤±è´¥')

    except Exception as e:
        print(f'  âŒ [{i}/{len(test_dates)}] {date} - é”™è¯¯: {e}')

print('\n' + '=' * 80)
print(f'æµ‹è¯•å®Œæˆï¼æˆåŠŸ: {success_count}/{len(test_dates)}')
print('=' * 80)

if success_count == len(test_dates):
    print('\nğŸŠ æµ‹è¯•é€šè¿‡ï¼æ‰€æœ‰æ•°æ®éƒ½åŒ…å«å®Œæ•´ç‰¹å¾')
else:
    print('\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®')

" > test_incremental_update.log 2>&1

echo ""
echo "âœ… æµ‹è¯•å®Œæˆ"
echo "ğŸ“„ æ—¥å¿—æ–‡ä»¶: test_incremental_update.log"
echo "ğŸ‘€ æŸ¥çœ‹å‘½ä»¤: cat test_incremental_update.log"
